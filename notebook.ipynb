{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85cc75af",
   "metadata": {},
   "source": [
    "# Unsupervised Handwritten Signature Verification System Using Extreme Learning Machine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f549483",
   "metadata": {},
   "source": [
    "## Overview \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945637dc",
   "metadata": {},
   "source": [
    "Unsupervised signature verification attempts to tell a forged signature from a real one based on the signature features alone. This idea is inspired by the existence of a generative model for genuine and forged signatures. This model generates a handwriting process for creating a genuine signature from a sequence of characters and generates an imitation process that omits some signature features for creating a skilled forgery of that signature. A method that could reverse this generative model would tell a genuine signature from a forged one without the need for ground truth training data samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd3030b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "151cfbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f63ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn_extensions\n",
      "  Downloading sklearn-extensions-0.0.2.tar.gz (19 kB)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\micky darlyn\\anaconda3\\lib\\site-packages (from sklearn_extensions) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn>=0.15 in c:\\users\\micky darlyn\\anaconda3\\lib\\site-packages (from sklearn_extensions) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.16.0 in c:\\users\\micky darlyn\\anaconda3\\lib\\site-packages (from sklearn_extensions) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\micky darlyn\\anaconda3\\lib\\site-packages (from scikit-learn>=0.15->sklearn_extensions) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\micky darlyn\\anaconda3\\lib\\site-packages (from scikit-learn>=0.15->sklearn_extensions) (2.2.0)\n",
      "Building wheels for collected packages: sklearn-extensions\n",
      "  Building wheel for sklearn-extensions (setup.py): started\n",
      "  Building wheel for sklearn-extensions (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn-extensions: filename=sklearn_extensions-0.0.2-py2.py3-none-any.whl size=24578 sha256=5a9c4a43d5770153ecf9301b9b0d72bfdb12b0180b67a4fafaa5399088144338\n",
      "  Stored in directory: c:\\users\\micky darlyn\\appdata\\local\\pip\\cache\\wheels\\5b\\4f\\12\\e56caf24d4ce8e90d3734238d9307c12b1d6c1a211889d85a4\n",
      "Successfully built sklearn-extensions\n",
      "Installing collected packages: sklearn-extensions\n",
      "Successfully installed sklearn-extensions-0.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42bf7107",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn_extensions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MICKYD~1\\AppData\\Local\\Temp/ipykernel_2928/2871359101.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn_extensions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextreme_learning_machines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRBFSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn_extensions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextreme_learning_machines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mELMRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn_extensions'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf17f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac55cac0",
   "metadata": {},
   "source": [
    "### Getting signature images into workspace \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcd65bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrating the genuine and forged image paths tor test \n",
    "\n",
    "test_genuine_image_paths = []\n",
    "test_forged_image_paths = []\n",
    "\n",
    "# for genuine\n",
    "for i in range (1,151):\n",
    "    directroy_path = f\"./New folder (10)/test/{i}/genuine/\"    \n",
    "    for file in os.listdir(directroy_path):\n",
    "        test_genuine_image_paths.append(file)\n",
    "        \n",
    "        \n",
    "# for forged \n",
    "for i in range (1,151):\n",
    "    directroy_path = f\"./New folder (10)/test/{i}/forge/\"    \n",
    "    for file in os.listdir(directroy_path):\n",
    "        test_forged_image_paths.append(file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e07ee2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "2100\n"
     ]
    }
   ],
   "source": [
    "print(len(test_genuine_image_paths))\n",
    "print(len(test_forged_image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "daddb39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrating the genuine and forged image paths tor train \n",
    "\n",
    "train_genuine_image_paths = []\n",
    "train_forged_image_paths = []\n",
    "\n",
    "# for genuine\n",
    "for i in range (1,151):\n",
    "    directroy_path = f\"./New folder (10)/train/genuine/\"    \n",
    "    for file in os.listdir(directroy_path):\n",
    "        train_genuine_image_paths.append(file)\n",
    "        \n",
    "        \n",
    "# for forged \n",
    "for i in range (1,151):\n",
    "    directroy_path = f\"./New folder (10)/train/forge/\"    \n",
    "    for file in os.listdir(directroy_path):\n",
    "        train_forged_image_paths.append(file)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80089a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360000\n",
      "360000\n"
     ]
    }
   ],
   "source": [
    "training_image_paths = []\n",
    "print(len(train_genuine_image_paths))\n",
    "print(len(train_forged_image_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66961560",
   "metadata": {},
   "source": [
    "### Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e411512",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from skimage.util import view_as_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d17411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extration using the inceptionV3 model\n",
    "\n",
    "def extract_features(image, model):\n",
    "    # Resize the image to 299x299 to match the input size of the InceptionV3 model\n",
    "    image = tf.image.resize(image, (299, 299))\n",
    "    \n",
    "    # Preprocess the image for input to the InceptionV3 model\n",
    "    image = preprocess_input(image)\n",
    "    \n",
    "    # Use the InceptionV3 model to extract features from the image\n",
    "    features = model.predict(np.array([image]))\n",
    "    \n",
    "    # Flatten the features into a 1D array\n",
    "    features = features.flatten()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad736b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to hold all image features \n",
    "signature_features = []\n",
    "\n",
    "\n",
    "for path in training_image_paths:\n",
    "    feature = extract_features(path,InceptionV3)\n",
    "    signature_features.append(feature)\n",
    "    \n",
    "X = np.array(signature_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c6825f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micky Darlyn\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass neg_label=-1, pos_label=1 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RBFSampler' from 'sklearn_extensions.extreme_learning_machines.random_layer' (C:\\Users\\Micky Darlyn\\anaconda3\\lib\\site-packages\\sklearn_extensions\\extreme_learning_machines\\random_layer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MICKYD~1\\AppData\\Local\\Temp/ipykernel_2928/2871359101.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn_extensions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextreme_learning_machines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRBFSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn_extensions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextreme_learning_machines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mELMRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'RBFSampler' from 'sklearn_extensions.extreme_learning_machines.random_layer' (C:\\Users\\Micky Darlyn\\anaconda3\\lib\\site-packages\\sklearn_extensions\\extreme_learning_machines\\random_layer.py)"
     ]
    }
   ],
   "source": [
    "from sklearn_extensions.extreme_learning_machines.random_layer import RBFSampler\n",
    "from sklearn_extensions.extreme_learning_machines.elm import ELMRegressor\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd21755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnsupervisedELM:\n",
    "    def __init__(self, density=0.01, l2_regularization=0.01, min_neurons=2, max_neurons=32768):\n",
    "        self.density = density\n",
    "        self.l2_regularization = l2_regularization\n",
    "        self.min_neurons = min_neurons\n",
    "        self.max_neurons = max_neurons\n",
    "        self.elm_model = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        num_features = X.shape[1]\n",
    "        num_neurons_list = np.logspace(np.log2(self.min_neurons), np.log2(self.max_neurons), num=20, base=2, dtype=int)\n",
    "        rp_layer = RBFSampler(gamma=1.0 / num_features, n_components=num_neurons_list[0], random_state=0, density=self.density)\n",
    "        rp_layer.fit(X)\n",
    "        hidden_output = rp_layer.transform(X)\n",
    "        for n in num_neurons_list[1:]:\n",
    "            rp_layer = RBFSampler(gamma=1.0 / num_features, n_components=n, random_state=0, density=self.density)\n",
    "            rp_layer.fit(X)\n",
    "            hidden_output = np.concatenate([hidden_output, rp_layer.transform(X)], axis=1)\n",
    "            kmeans = KMeans(n_clusters=n, random_state=0).fit(hidden_output)\n",
    "            hidden_output = kmeans.transform(hidden_output)\n",
    "        self.elm_model = ELMRegressor(n_hidden=num_neurons_list[-1], alpha=self.l2_regularization)\n",
    "        self.elm_model.fit(hidden_output)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        hidden_output = self.elm_model.random_layer.transform(X)\n",
    "        for kmeans in self.elm_model.hidden_layer:\n",
    "            hidden_output = kmeans.transform(hidden_output)\n",
    "        return self.elm_model.output_layer.predict(hidden_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
